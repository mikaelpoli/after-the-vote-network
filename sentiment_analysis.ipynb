{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d13d88",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d015b59e",
   "metadata": {},
   "source": [
    "## Description\n",
    "Perform sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2692be6",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24e5dca",
   "metadata": {},
   "source": [
    "### Libraries (Pyhton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742836dd",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b7927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    BASE_DIR = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    BASE_DIR = Path().resolve()\n",
    "\n",
    "SRC_DIR = BASE_DIR / 'src'\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "POSTS_DIR = DATA_DIR / 'posts'\n",
    "POSTS_ALL_DIR = POSTS_DIR / 'all'\n",
    "POSTS_FILTERED_DIR = POSTS_DIR / 'filtered'\n",
    "POSTS_FILTERED_CLEAN_DIR = POSTS_FILTERED_DIR / 'clean'\n",
    "COMMENTS_DIR = DATA_DIR / 'comments'\n",
    "COMMENTS_CLEAN_DIR = COMMENTS_DIR / 'clean'\n",
    "RESULTS_DIR = BASE_DIR / 'results'\n",
    "RESULTS_GRAPHS_DIR = RESULTS_DIR / 'graphs'\n",
    "RESULTS_MODELS_DIR = RESULTS_DIR / 'models'\n",
    "RESULTS_MODELS_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_MODELS_FILE = RESULTS_MODELS_DIR / 'model_results.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3951200a",
   "metadata": {},
   "source": [
    "### Libraries (Custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57185792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a62e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import topic as t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671cc6a8",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "38022802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH UNW- 15819 924974 -- \n",
      "+ attr: edge_default (g), node_default (g), _nx_name (v), name (v), weight (e)\n"
     ]
    }
   ],
   "source": [
    "# Graph\n",
    "filename = RESULTS_GRAPHS_DIR / 'g_dd.graphml'\n",
    "g_dd_nx = nx.read_graphml(str(filename))\n",
    "g_dd = ig.Graph.from_networkx(g_dd_nx)\n",
    "\n",
    "print(g_dd.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46a5fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrices\n",
    "filename_pickle_gdd = RESULTS_GRAPHS_DIR / 'g_dd.pickle'\n",
    "with open(filename_pickle_gdd , 'rb') as f:\n",
    "    g_dd_matrices = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "850eb02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original documents\n",
    "filename_df = DATA_DIR / 'df_dd.json'\n",
    "df_dd = pd.read_json(str(filename_df), lines=True)\n",
    "leiden_topics = list(df_dd['leiden_topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "19d67c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIWC-22 Results\n",
    "cols_in = ['document_id', 'leiden_topic', 'tone_pos', 'tone_neg', 'emo_pos', 'emo_neg', 'politic', 'health', 'mental']\n",
    "filename_liwc_results = RESULTS_MODELS_DIR / 'liwc-22' / 'liwc-22-results.csv'\n",
    "df = pd.read_csv(filename_liwc_results, usecols=cols_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "584b7185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERTAgent scores\n",
    "filename_bertagent_scores = RESULTS_MODELS_DIR / 'bertagent' / 'data' / 'bertagent_scores.json'\n",
    "with open(filename_bertagent_scores, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    bertagent_scores = json.load(f)\n",
    "bertagent_scores_int = {int(k): v for k, v in bertagent_scores.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc02ce22",
   "metadata": {},
   "source": [
    "## Preprocess Text for BERTAgent\n",
    "For efficiency, extract only the first 15 top documents per topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d06d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 15 documents per topic\n",
    "repr_docs_idx_leiden = t.get_louvain_community_reps(g_dd, leiden_topics, top_k=15)\n",
    "doc_id_to_text = dict(zip(df_dd['document_id'], df_dd['og_text']))\n",
    "\n",
    "# Build the new dictionary\n",
    "repr_docs_text_leiden = {\n",
    "    topic: [doc_id_to_text[doc_id] for doc_id in doc_ids if doc_id in doc_id_to_text]\n",
    "    for topic, doc_ids in repr_docs_idx_leiden.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd73e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the dictionary into a list of dicts, removing outlier topics\n",
    "rows = [\n",
    "    {\"leiden_topic\": topic, \"text\": text}\n",
    "    for topic, texts in repr_docs_text_leiden.items() if topic<=12\n",
    "    for text in texts\n",
    "]\n",
    "\n",
    "# Create the DataFrame\n",
    "df_repr_docs = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69e14628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to .csv\n",
    "filename_repr_docs = RESULTS_MODELS_DIR / 'bertagent' / 'data' / 'repr_docs.csv'\n",
    "df_repr_docs['text'] = df_repr_docs['text'].astype(str)\n",
    "df_repr_docs.to_csv(filename_repr_docs, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39bb804",
   "metadata": {},
   "source": [
    "## LIWC-22 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3d01b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate composite \"positive emotion\" score\n",
    "df[\"emotion\"] = df[\"emo_pos\"] - df[\"emo_neg\"]\n",
    "\n",
    "# Calculate composite \"tone\" score\n",
    "df[\"tone\"] = df[\"tone_pos\"] - df[\"tone_neg\"]\n",
    "\n",
    "# Map BERTAgent scores to topic\n",
    "df['agency'] = df['leiden_topic'].map(bertagent_scores_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "303cee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign attributes from LIWC-22 and BERTAgent to nodes\n",
    "attributes_to_assign = [\n",
    "    'leiden_topic', 'emotion', 'tone', 'mental', 'health',\n",
    "    'politic', 'agency'\n",
    "]\n",
    "\n",
    "# Create a lookup dictionary from the DataFrame\n",
    "df_copy = copy.deepcopy(df)\n",
    "df_copy.set_index('document_id', inplace=True)\n",
    "attr_dict = df_copy[attributes_to_assign].to_dict(orient='index')\n",
    "\n",
    "# Iterate over nodes and assign attributes\n",
    "for v in g_dd.vs:\n",
    "    doc_id = v['name']\n",
    "    if doc_id in attr_dict:\n",
    "        for attr, value in attr_dict[doc_id].items():\n",
    "            v[attr] = value\n",
    "    else:\n",
    "        print(f\"Warning: document_id {doc_id} not found in DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9559452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to graphml\n",
    "filename_graph = RESULTS_GRAPHS_DIR / 'sentiment_graph.graphml'\n",
    "g_dd.write_graphml(str(filename_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872bfae3",
   "metadata": {},
   "source": [
    "### Build Topic Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbe426e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract C\n",
    "topics = list(df['leiden_topic'])\n",
    "num_docs, num_topics, C = t.extract_community_assignments(topics, topic_ids_start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6376910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize existing matrices\n",
    "Pwd = g_dd_matrices['Pwd'] / g_dd_matrices['Pwd'].sum()\n",
    "Pdd = g_dd_matrices['Pdd'] / g_dd_matrices['Pdd'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4791265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update topic matrices\n",
    "Pwc = Pwd.dot(C)              # Joint word + class probability\n",
    "Pcc = ((C.T).dot(Pdd)).dot(C) # Joint class + class probability\n",
    "pc = Pcc.sum(axis=0)          # Topic co-occurrence weights (node strength of each topic in the topic co-occurrence matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "0b3c5260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom topic labels\n",
    "filename_leiden_custom_topics = RESULTS_MODELS_DIR / 'leiden' / 'custom_topics_sorted.json'\n",
    "with open(filename_leiden_custom_topics, 'r') as f:\n",
    "    custom_topic_labels = json.load(f)\n",
    "\n",
    "labs = {str(k): v for k, v in custom_topic_labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "b2bd9d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of metrics to aggregate\n",
    "metrics = ['politic', 'mental', 'health', 'emotion', 'tone', 'agency']\n",
    "\n",
    "# Group by topic and compute means\n",
    "topic_df = df.groupby('leiden_topic')[metrics].mean().reset_index()\n",
    "topic_df['node_strength'] = np.array(pc)[0]\n",
    "topic_df['agency'] = topic_df['agency'].fillna(0.0)\n",
    "topic_df['topic_label'] = topic_df['leiden_topic'].astype(str).map(labs)\n",
    "\n",
    "# Ignore outlier data\n",
    "mask = topic_df['topic_label'].str.contains('Outliers', na=False)\n",
    "cols_to_zero = topic_df.columns.difference(['leiden_topic', 'topic_label'])\n",
    "topic_df.loc[mask, cols_to_zero] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "234cf5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of topics\n",
    "n_topics = Pcc.shape[0]\n",
    "\n",
    "# Create a graph with n_topics nodes\n",
    "g_topic = ig.Graph()\n",
    "g_topic.add_vertices(n_topics)\n",
    "\n",
    "# Add node attribute: topic ID\n",
    "g_topic.vs['leiden_topic'] = list(range(n_topics))\n",
    "\n",
    "# Set mean attributes on each topic node\n",
    "attributes = [col for col in topic_df.columns if col != 'leiden_topic']\n",
    "for attr in attributes:\n",
    "    # Map from leiden_topic -> value\n",
    "    values = topic_df.set_index('leiden_topic')[attr]\n",
    "    g_topic.vs[attr] = [values.get(t, None) for t in g_topic.vs['leiden_topic']]\n",
    "\n",
    "# Build edges from upper triangle of the Pcc matrix (symmetric)\n",
    "edges = []\n",
    "weights = []\n",
    "\n",
    "for i in range(n_topics):\n",
    "    for j in range(i+1, n_topics):\n",
    "        weight = Pcc[i, j]\n",
    "        if weight > 0.0:  # Only keep non-zero edges\n",
    "            edges.append((i, j))\n",
    "            weights.append(weight)\n",
    "\n",
    "# Add edges and their weights\n",
    "g_topic.add_edges(edges)\n",
    "g_topic.es['weight'] = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "1b2a51cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to graphml\n",
    "filename_topic_graph = RESULTS_GRAPHS_DIR / 'topics_graph.graphml'\n",
    "g_topic.write_graphml(str(filename_topic_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca7601",
   "metadata": {},
   "source": [
    "## Clear Allocated Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c00eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run before exiting the program to clear memory\n",
    "%reset -f\n",
    "import gc\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
