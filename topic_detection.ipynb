{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730b97b8",
   "metadata": {},
   "source": [
    "# Topic Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ac7e85",
   "metadata": {},
   "source": [
    "## Description\n",
    "Perform topic detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c67fb2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7990d3",
   "metadata": {},
   "source": [
    "### Libraries (Pyhton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e963b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import community as community_louvain\n",
    "import igraph as ig\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7288f78",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e29eb0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    BASE_DIR = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    BASE_DIR = Path().resolve()\n",
    "\n",
    "SRC_DIR = BASE_DIR / 'src'\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "POSTS_DIR = DATA_DIR / 'posts'\n",
    "POSTS_ALL_DIR = POSTS_DIR / 'all'\n",
    "POSTS_FILTERED_DIR = POSTS_DIR / 'filtered'\n",
    "POSTS_FILTERED_CLEAN_DIR = POSTS_FILTERED_DIR / 'clean'\n",
    "COMMENTS_DIR = DATA_DIR / 'comments'\n",
    "COMMENTS_CLEAN_DIR = COMMENTS_DIR / 'clean'\n",
    "RESULTS_DIR = BASE_DIR / 'results'\n",
    "RESULTS_GRAPHS_DIR = RESULTS_DIR / 'graphs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d257eafa",
   "metadata": {},
   "source": [
    "### Libraries (Custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c3045b",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e7b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_df = DATA_DIR / 'data.json'\n",
    "df = pd.read_json(str(filename_df), lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1550f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>root_post_id</th>\n",
       "      <th>document_type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>filtered_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1h7okhk</td>\n",
       "      <td>1h7okhk</td>\n",
       "      <td>post</td>\n",
       "      <td>asktransgender</td>\n",
       "      <td>[this PRON, normal ADJ, this PRON, i PRON, nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ht5ang</td>\n",
       "      <td>1ht5ang</td>\n",
       "      <td>post</td>\n",
       "      <td>asktransgender</td>\n",
       "      <td>[i PRON, just ADV, find VERB, i PRON, girl NOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1haqyqt</td>\n",
       "      <td>1haqyqt</td>\n",
       "      <td>post</td>\n",
       "      <td>asktransgender</td>\n",
       "      <td>[trans PROPN, girl NOUN, who PRON, come VERB, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1hong9g</td>\n",
       "      <td>1hong9g</td>\n",
       "      <td>post</td>\n",
       "      <td>asktransgender</td>\n",
       "      <td>[my PRON, partner NOUN, get VERB, want VERB, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1hhl0q7</td>\n",
       "      <td>1hhl0q7</td>\n",
       "      <td>post</td>\n",
       "      <td>asktransgender</td>\n",
       "      <td>[so ADV, i PRON, find VERB, my PRON, trans PRO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document_id root_post_id document_type       subreddit  \\\n",
       "0     1h7okhk      1h7okhk          post  asktransgender   \n",
       "1     1ht5ang      1ht5ang          post  asktransgender   \n",
       "2     1haqyqt      1haqyqt          post  asktransgender   \n",
       "3     1hong9g      1hong9g          post  asktransgender   \n",
       "4     1hhl0q7      1hhl0q7          post  asktransgender   \n",
       "\n",
       "                                        filtered_pos  \n",
       "0  [this PRON, normal ADJ, this PRON, i PRON, nor...  \n",
       "1  [i PRON, just ADV, find VERB, i PRON, girl NOU...  \n",
       "2  [trans PROPN, girl NOUN, who PRON, come VERB, ...  \n",
       "3  [my PRON, partner NOUN, get VERB, want VERB, g...  \n",
       "4  [so ADV, i PRON, find VERB, my PRON, trans PRO...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22e2f86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH UNW- 15819 924974 -- \n",
      "+ attr: edge_default (g), node_default (g), _nx_name (v), name (v), weight (e)\n"
     ]
    }
   ],
   "source": [
    "filename = RESULTS_GRAPHS_DIR / 'g_dd.graphml'\n",
    "g_dd_nx = nx.read_graphml(str(filename))\n",
    "g_dd = ig.Graph.from_networkx(g_dd_nx)\n",
    "\n",
    "print(g_dd.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "272c10ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Document-Projected Network (Giant Component) ---\n",
      "Size: 15819\n",
      "Average degree: 116.94\n",
      "Median degree: 50.00\n",
      "Density: 0.00739\n",
      "Diameter: 6.00\n",
      "Average path length: 2.51146\n"
     ]
    }
   ],
   "source": [
    "# Check basic stats\n",
    "print(\"--- Document-Projected Network (Giant Component) ---\")\n",
    "print(f\"Size: {g_dd.vcount()}\")\n",
    "print(f\"Average degree: {np.mean(g_dd.degree()):.2f}\")\n",
    "print(f\"Median degree: {np.median(g_dd.degree()):.2f}\")\n",
    "print(f\"Density: {g_dd.density():.5f}\")\n",
    "print(f\"Diameter: {g_dd.diameter(directed=False, unconn=False):.2f}\")\n",
    "print(f\"Average path length: {g_dd.average_path_length():.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c35f52",
   "metadata": {},
   "source": [
    "### Retrieve Original Text\n",
    "Retrieve the original non-processed text from the documents in the network (giant component of Pdd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a26528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get node names in a list\n",
    "# Get df indices in a list\n",
    "# Select Reddit id (column 'document_id') from documents in df whose index is in the node names list\n",
    "# Load \"all posts clean\" and \"all comments clean\"\n",
    "# In \"all posts clean\", create a \"og_text\" column containing the text in \"title\" and \"selftext\", concatenated.\n",
    "# In \"all comments clean\", create a \"og_text\" column containing the text in \"comment_body\"\n",
    "# Merge the two dfs so that posts and comments are in the same dataframe: be careful, do not discared \"document_id\"\n",
    "# Add and \"og_text\" column to df, based on \"document_id\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36270792",
   "metadata": {},
   "source": [
    "## Louvain\n",
    "Run Louvain on the largest connected component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997551c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Louvain\n",
    "# partition_lcc = community_louvain.best_partition(g_dd, weight='weight')\n",
    "# print(f\"Louvain (LCC) found {len(set(partition_lcc.values()))} communities.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d00cd",
   "metadata": {},
   "source": [
    "## Clear Allocated Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bd0f078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run before exiting the program to clear memory\n",
    "%reset -f\n",
    "import gc\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
